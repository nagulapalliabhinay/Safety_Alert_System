{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the required libraries\n",
    "# !pip install imutils\n",
    "# !conda install -c conda-forge dlib # If this takes a lot of time, try and run it on anaconda prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import dlib\n",
    "import cv2\n",
    "import smtplib\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import time\n",
    "import winsound\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "from datetime import datetime\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Install OpenCV With CUDA GPU Support on Windows 10. Reference the link below\n",
    "# https://www.youtube.com/watch?v=YsmhKar8oOc&t=0s\n",
    "\n",
    "# To check if the opencv is cuda enabled\n",
    "print(cv2.__version__)\n",
    "def is_cuda_cv(): # 1 == using cuda, 0 = not using cuda\n",
    "    try:\n",
    "        count = cv2.cuda.getCudaEnabledDeviceCount()\n",
    "        if count > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Reference:    \n",
    "# https://stackoverflow.com/questions/61492452/how-to-check-if-opencv-is-using-gpu-or-not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv3 For Cell phone Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the YOLO model\n",
    "net = cv2.dnn.readNet('models/yolov3.weights', 'models/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set CUDA as the preferable backend and target\n",
    "# To use Graphic card\n",
    "# This block of code runs only if OpenCV with CUDA is installed.\n",
    "if is_cuda_cv():\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting all the objects from coco\n",
    "\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "classes # These are all the objects that YOLOv3 model can detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of object detection using YOLOv3\n",
    "\n",
    "def yolo_obj_dec(img, net, size, confidence_threshold, threshold, objects):\n",
    "\n",
    "    # getting the height and width of the image.\n",
    "    img_height, img_width, _ = img.shape\n",
    "    \n",
    "    # Setting up the output layer\n",
    "    output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "    # print(output_layer_names)\n",
    "    layers = net.getLayerNames()\n",
    "    layers = [layers[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # print(layerOutputs)\n",
    "    \n",
    "    \n",
    "    # Setting input layer by normalizing the images (Resizing the Image)\n",
    "    net.setInput(cv2.dnn.blobFromImage(img, 1/255.0, (size, size), swapRB=True, crop=False))\n",
    "    layerOutputs = net.forward(layers)\n",
    "\n",
    "    # Bounding boxes, confidences, object_ids\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    # getting the info about the condidences,class ids\n",
    "    # first values are the locations of the bounding boxes\n",
    "    # fifth value is the box confidence.\n",
    "    # x,y,wh,w boundary box\n",
    "    # x,y are center of the object and w and h are size i.e width and the height of the object.\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:] #all the egithy objects predictions\n",
    "            # print(scores)\n",
    "            class_id = np.argmax(scores) # high scores \n",
    "            confidence = scores[class_id] # high scores\n",
    "            if confidence > confidence_threshold:\n",
    "                center_x = int(detection[0]*img_width) # Nomalizing\n",
    "                center_y = int(detection[1]*img_height)\n",
    "                w = int(detection[2]*img_width)\n",
    "                h = int(detection[3]*img_height)\n",
    "                x = int(center_x - w/2) # for corners\n",
    "                y = int(center_y - h/2)\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                # print(boxes)\n",
    "                # print(confidences)\n",
    "    \n",
    "    # Non maximum suppression to keep the highest scored boxes out of multiple boxes on a same object.\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, threshold)\n",
    "    # print(indexes.flatten()) # To see Redundant boxes\n",
    "    \n",
    "    result = []\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            \n",
    "            result.append((label, confidence, x, y, w, h))\n",
    "    \n",
    "\n",
    "\n",
    "    return img_width, img_height,result\n",
    "    \n",
    "    \n",
    "    \n",
    "# Reference:\n",
    "# https://www.youtube.com/watch?v=1LCb1PVqzeY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drowsiness detection Using Face Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "# Reference: https://www.pyimagesearch.com/2017/05/08/drowsiness-detection-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the face landmark detectors and predictors\n",
    "\n",
    "face_landmarks =  'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(face_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Co-ordinates of Left-Eye and Right-Eye\n",
    "\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"] # starting and ending cordinates of left eye\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"] # starting and ending cordinates of right eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yawn Detection and Counter Using Face Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mouth_open(shape):\n",
    "    upper_lip = np.concatenate((shape[50:53], shape[61:64]))\n",
    "    low_lip = np.concatenate((shape[56:59], shape[65:68]))\n",
    "\n",
    "    upper_mean = np.mean( upper_lip, axis=0)\n",
    "    low_mean = np.mean(low_lip, axis=0)\n",
    "\n",
    "    distance = abs(upper_mean[1] - low_mean[1])\n",
    "    return distance\n",
    "\n",
    "# Reference:\n",
    "# https://medium.com/analytics-vidhya/yawn-detection-using-opencv-and-dlib-e04ba79b9936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alarm Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alarm():\n",
    "    winsound.PlaySound('alarm.wav', winsound.SND_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mail Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Send_email(txt):\n",
    "    sender_email_id = 'driveralertAI@gmail.com'\n",
    "    sender_email_pass = 'Driver@1234'\n",
    "    receiver_email_id = 'n.abhinay00@gmail.com'\n",
    "    \n",
    "    # creates SMTP session \n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587)  \n",
    "    s.starttls() \n",
    "    s.login(sender_email_id, sender_email_pass) \n",
    "    time = datetime.now()\n",
    "    curr_time = time.strftime(\"%H:%M:%S\")\n",
    "    msg = MIMEMultipart()\n",
    "    msg[\"From\"] = sender_email_id\n",
    "    msg[\"To\"] = receiver_email_id\n",
    "    msg[\"Subject\"] = 'Driving Alert triggered at: ' + str(curr_time)\n",
    "    msg.attach(MIMEText(txt, 'plain'))\n",
    "    s.sendmail(sender_email_id, receiver_email_id, msg.as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting thresholds and initializing the counters\n",
    "Eye_Threshold = 0.27\n",
    "Eye_AR_Frames = 10 \n",
    "Drowsy_Counter = 0\n",
    "Yawn_Threshold = 18\n",
    "Yawn_Counter = 0\n",
    "CellPhone_Counter=0\n",
    "CellPhone_Threshold=10\n",
    "count_yawn = 0\n",
    "total_yawn = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Capturing and Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting the Camera\\n\")\n",
    "cap = cv2.VideoCapture(1) # pass 0 if you want to use inbuilt camera, 1 if you want to use USB camera.\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    size = 416\n",
    "    confidence_threshold = 0.5 # Minimum confidence\n",
    "    threshold = 0.4\n",
    "    img_width, img_height, result= yolo_obj_dec(img, net, size, confidence_threshold, threshold, classes)\n",
    "\n",
    "    # Cell Phone Detection\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in result:\n",
    "        label, confidence, x, y, w, h = i\n",
    "        \n",
    "        if label == \"person\":\n",
    "            # print(\"Person Detected\\n\")\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "            cv2.putText(img, label + confidence + \" confidence\", (x, y+20), font, 2, (255, 255, 255), 2)\n",
    "    \n",
    "        # checking for cell phone in Image\n",
    "        if label == \"cell phone\":\n",
    "            print(\"cell phone detected\\n\")\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "            cv2.putText(img, label + \" Detected \"+confidence + \" confidence\", (x, y+20), font, 2, (255, 255, 255), 2)\n",
    "            CellPhone_Counter+=1\n",
    "        \n",
    "        if CellPhone_Counter >= CellPhone_Threshold:\n",
    "            Alarm()\n",
    "            Send_email('Cell Phone usage detected while driving')\n",
    "            CellPhone_Counter = 0\n",
    "            \n",
    "    # Drowsiness Detection & Yawn Detection and Count  \n",
    "    img = imutils.resize(img, width=450) # \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converting image to gray scale\n",
    "    # detecting the face in the image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    for i in rects:\n",
    "        shape = predictor(gray, i)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        avg_ear = (leftEAR + rightEAR) / 2.0 #average eye aspect ratio\n",
    "        # Yawn\n",
    "        distance = Mouth_open(shape)\n",
    "        \n",
    "        # drawing eye boundaries on image\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "\n",
    "        cv2.drawContours(img, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(img, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "        # Checking for drowsiness\n",
    "        if avg_ear < Eye_Threshold:\n",
    "            Drowsy_Counter += 1\n",
    "            \n",
    "            if Drowsy_Counter >= Eye_AR_Frames:\n",
    "                print('Driver is Feeling Drowsy\\n')\n",
    "                Alarm()\n",
    "                Send_email('Driver is Feeling Drowsy')\n",
    "                Drowsy_Counter = 0\n",
    "                cv2.putText(img, \"Drowsiness Detected\", (10, 30), font, 2, (255, 255, 255), 2)\n",
    "            \n",
    "       # Yawn Detection and Counting    \n",
    "        else:\n",
    "            Drowsy_Counter = 0\n",
    "            if (distance > Yawn_Threshold):\n",
    "                    Yawn_Counter +=1\n",
    "                    cv2.putText(img, str(Yawn_Counter), (100, 60),font, 1.5, (0, 0, 255), 2)\n",
    "                    if Yawn_Counter >= 7:\n",
    "                        count_yawn += 1\n",
    "                        total_yawn += 1\n",
    "                        # print(\" Driver is Yawning.\")\n",
    "                        cv2.putText(img, \"Yawning\", (100, 60),font, 1.5, (0, 0, 255), 2)\n",
    "                        Yawn_Counter = 0\n",
    "                        \n",
    "                    # if greaterthan or equal to three yawns are detected\n",
    "                    if count_yawn >= 3: \n",
    "                        print(\" Driver is Yawning. Might be Exhausted. Yawn Count: \"+ str(total_yawn))\n",
    "                        Alarm()\n",
    "                        Send_email(\"Driver is Yawning. Might be Exhausted\")\n",
    "                        count_yawn=0\n",
    "                        \n",
    "    cv2.putText(img, \"EAR: {:.2f}\".format(avg_ear), (300, 30), font, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(img, \"Lip Distance: {:.2f}\".format(distance), (300, 60), font, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(img, \"Yawn count :{:.2f}\".format(total_yawn), (280,90),font, 1, (0, 0, 255), 2)\n",
    "            \n",
    "                       \n",
    "    cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27: # break if pressed esc key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
